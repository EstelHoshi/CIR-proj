{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection Movement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import imutils\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init camera\n",
    "camera = Camera.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_detection(firstFrame, camera):\n",
    "    \"\"\"\n",
    "    Detect motion by comparing the current camera frame with a firstFrame.\n",
    "    \n",
    "    Arguments:\n",
    "        firstFrame (array): first frame considered as the baseline\n",
    "        camera (Camera): instantiated Jetbot camera, used to obtain new frames.\n",
    "        \n",
    "    Returns:\n",
    "        list: of regions where movement has been detected (left, top, right, bottom)\n",
    "    \"\"\"\n",
    "    # Adapted from https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/\n",
    "\n",
    "    # Min movement area\n",
    "    MIN_AREA = 50\n",
    "\n",
    "    # Gaussian blur kernel\n",
    "    KERNEL_SIZE = 3\n",
    "\n",
    "    # Movement hreshold\n",
    "    THRESHOLD = 37\n",
    "\n",
    "    # List to store regions where movement is detected\n",
    "    motion_bboxes = []\n",
    "    \n",
    "    # firstFrame preprocessing\n",
    "    firstFrame = cv2.cvtColor(firstFrame, cv2.COLOR_BGR2GRAY)\n",
    "    firstFrame = cv2.GaussianBlur(firstFrame, (KERNEL_SIZE, KERNEL_SIZE), 0)\n",
    "\n",
    "    ff_widget.value = bgr8_to_jpeg(firstFrame)\n",
    "    \n",
    "    # grab the current frame and initialize the static/moving text\n",
    "    frame = camera.value.copy()\n",
    "\n",
    "    # convert frame to grayscale, and blur it\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (KERNEL_SIZE, KERNEL_SIZE), 0)\n",
    "\n",
    "    # compute the absolute difference between the current frame and\n",
    "    # first frame\n",
    "    frameDelta = cv2.absdiff(firstFrame, gray)\n",
    "    thresh = cv2.threshold(frameDelta, THRESHOLD, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # dilate the thresholded image to fill in holes, then find contours\n",
    "    # on thresholded image\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)   \n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # if the contour is too small, ignore it\n",
    "        if cv2.contourArea(c) < MIN_AREA:\n",
    "            continue\n",
    "\n",
    "        # compute the bounding box for the contour, draw it on the frame,\n",
    "        # and update the text\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        \n",
    "        motion_bboxes.append((x, y, x+w, y+h))    # (left, top, right, bottom)\n",
    "\n",
    "    # Display image frame\n",
    "    image_widget.value = bgr8_to_jpeg(frame)\n",
    "    dif_widget.value = bgr8_to_jpeg(thresh)\n",
    "    \n",
    "    return motion_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677795d9f584489499a4f193a67b1cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='400', width='400'), Image(value=b'', format='jpeg', heiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image widget\n",
    "image_widget = widgets.Image(format='jpeg', width=400, height=400)\n",
    "dif_widget = widgets.Image(format='jpeg', width=400, height=400)\n",
    "ff_widget = widgets.Image(format='jpeg', width=400, height=400)\n",
    "\n",
    "display(widgets.HBox([ff_widget, image_widget, dif_widget]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "MAX_TIME = 10\n",
    "\n",
    "first_frame = camera.value.copy()\n",
    "\n",
    "motion_boxes = []\n",
    "t0 = time.time()\n",
    "elapsed_time = 0\n",
    "\n",
    "# Run motion detection for MAX_TIME\n",
    "while elapsed_time < MAX_TIME:\n",
    "    m_bboxes = motion_detection(first_frame, camera)\n",
    "    motion_boxes.extend(m_bboxes)\n",
    "    \n",
    "    elapsed_time =  time.time() - t0\n",
    "    \n",
    "motion_boxes = set(motion_boxes)    # remove duplicates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
